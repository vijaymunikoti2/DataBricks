{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6ed8f362-1643-481d-8e5f-69ffafcb04cf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "##/FileStore/tables/sample_json_file.json\n",
    "\n",
    "df=spark.read.json(\"/FileStore/tables/sample_json_file.json\",multiLine=True)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f679a2e-49be-400e-93a8-7724e1f9781b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, explode\n",
    "from pyspark.sql.types import StructType, ArrayType\n",
    "\n",
    "# Create Spark session\n",
    "spark = SparkSession.builder.appName(\"FlattenJSON\").getOrCreate()\n",
    "\n",
    "def flatten_df(nested_df):\n",
    "    flat_cols = []\n",
    "    nested_cols = []\n",
    "\n",
    "    for column_name, column_type in nested_df.dtypes:\n",
    "        if \".\" in column_name:\n",
    "            column_name = column_name.replace(\".\", \"_\")\n",
    "        if column_type.startswith(\"struct\"):\n",
    "            nested_cols.append(column_name)\n",
    "        elif column_type.startswith(\"array\"):\n",
    "            nested_cols.append(column_name)\n",
    "        else:\n",
    "            flat_cols.append(col(column_name))\n",
    "\n",
    "    while nested_cols:\n",
    "        col_name = nested_cols.pop(0)\n",
    "\n",
    "        # Check the column type\n",
    "        field_type = dict(nested_df.dtypes)[col_name]\n",
    "        if field_type.startswith(\"array\"):\n",
    "            nested_df = nested_df.withColumn(col_name, explode(col(col_name)))\n",
    "        else:\n",
    "            for field in nested_df.select(col_name + \".*\").columns:\n",
    "                nested_df = nested_df.withColumn(col_name + \"_\" + field, col(col_name + \".\" + field))\n",
    "            nested_df = nested_df.drop(col_name)\n",
    "\n",
    "        # Recalculate flat and nested columns\n",
    "        flat_cols = []\n",
    "        nested_cols = []\n",
    "        for column_name, column_type in nested_df.dtypes:\n",
    "            if \".\" in column_name:\n",
    "                column_name = column_name.replace(\".\", \"_\")\n",
    "            if column_type.startswith(\"struct\") or column_type.startswith(\"array\"):\n",
    "                nested_cols.append(column_name)\n",
    "            else:\n",
    "                flat_cols.append(col(column_name))\n",
    "\n",
    "    return nested_df\n",
    "\n",
    "# Example usage\n",
    "# Assuming you loaded a nested JSON file into `df`\n",
    "# df = spark.read.json(\"path_to_nested.json\")\n",
    "# flat_df = flatten_df(df)\n",
    "# flat_df.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d8395f84-3160-4fdd-b875-6ec18b8098f0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df2=flatten_df(df)\n",
    "display(df2)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "json",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
